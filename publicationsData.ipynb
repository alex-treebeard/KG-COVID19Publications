{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langdetect\n",
    "import string\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "# !pip install -U gensim --user\n",
    "import gensim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random, time\n",
    "import gzip, os, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check if there is any missing value in the dataset ###\n",
    "def check_missing(df, col):\n",
    "    missing  = 0\n",
    "    misVariables = []\n",
    "    CheckNull = df.isnull().sum()\n",
    "    for var in range(0, len(CheckNull)):\n",
    "#         if CheckNull[var] != 0:\n",
    "        misVariables.append([col[var], CheckNull[var], round(CheckNull[var]/len(df),3)])\n",
    "        missing = missing + 1\n",
    "\n",
    "    if missing == 0:\n",
    "        print('Dataset is complete with no blanks.')\n",
    "    else:\n",
    "        print('Totally, %d features have missing values (blanks).' %missing)\n",
    "        df_misVariables = pd.DataFrame.from_records(misVariables)\n",
    "        df_misVariables.columns = ['Variable', 'Missing', 'Percentage (%)']\n",
    "        s = df_misVariables.sort_values(by=['Percentage (%)'], ascending=False).style.bar(subset=['Percentage (%)'], color='#d65f5f')\n",
    "        display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally, 31 features have missing values (blanks).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row0_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 100.0%, transparent 100.0%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row1_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 96.7%, transparent 96.7%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row2_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 95.7%, transparent 95.7%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row3_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 84.1%, transparent 84.1%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row4_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 81.5%, transparent 81.5%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row5_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 70.5%, transparent 70.5%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row6_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 62.9%, transparent 62.9%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row7_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 58.0%, transparent 58.0%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row8_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 46.4%, transparent 46.4%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row9_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 45.3%, transparent 45.3%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row10_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 43.3%, transparent 43.3%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row11_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 42.0%, transparent 42.0%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row12_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 42.0%, transparent 42.0%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row13_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 42.0%, transparent 42.0%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row14_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 42.0%, transparent 42.0%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row15_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 37.7%, transparent 37.7%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row16_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 13.7%, transparent 13.7%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row17_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 6.3%, transparent 6.3%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row18_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 6.2%, transparent 6.2%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row19_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 4.3%, transparent 4.3%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row20_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 4.0%, transparent 4.0%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row21_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#d65f5f 4.0%, transparent 4.0%);\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row22_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row23_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row24_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row25_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row26_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row27_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row28_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row29_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_c9f2fa28_8315_11ea_8d71_0242ac110002row30_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }</style><table id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Variable</th>        <th class=\"col_heading level0 col1\" >Missing</th>        <th class=\"col_heading level0 col2\" >Percentage (%)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row0\" class=\"row_heading level0 row0\" >26</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row0_col0\" class=\"data row0 col0\" >UIDs of supporting grants</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row0_col1\" class=\"data row0 col1\" >11520</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row0_col2\" class=\"data row0 col2\" >0.951000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row1_col0\" class=\"data row1 col0\" >MeSH terms</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row1_col1\" class=\"data row1 col1\" >11151</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row1_col2\" class=\"data row1 col2\" >0.920000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row2\" class=\"row_heading level0 row2\" >25</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row2_col0\" class=\"data row2 col0\" >Funder</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row2_col1\" class=\"data row2 col1\" >11030</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row2_col2\" class=\"data row2 col2\" >0.910000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row3_col0\" class=\"data row3 col0\" >PMCID</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row3_col1\" class=\"data row3 col1\" >9692</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row3_col2\" class=\"data row3 col2\" >0.800000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row4\" class=\"row_heading level0 row4\" >19</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row4_col0\" class=\"data row4 col0\" >Corresponding Authors</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row4_col1\" class=\"data row4 col1\" >9390</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row4_col2\" class=\"data row4 col2\" >0.775000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row5\" class=\"row_heading level0 row5\" >14</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row5_col0\" class=\"data row5 col0\" >Issue</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row5_col1\" class=\"data row5 col1\" >8119</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row5_col2\" class=\"data row5 col2\" >0.670000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row6\" class=\"row_heading level0 row6\" >13</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row6_col0\" class=\"data row6 col0\" >Volume</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row6_col1\" class=\"data row6 col1\" >7249</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row6_col2\" class=\"data row6 col2\" >0.598000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row7\" class=\"row_heading level0 row7\" >3</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row7_col0\" class=\"data row7 col0\" >PMID</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row7_col1\" class=\"data row7 col1\" >6690</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row7_col2\" class=\"data row7 col2\" >0.552000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row8\" class=\"row_heading level0 row8\" >29</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row8_col0\" class=\"data row8 col0\" >Source Linkout</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row8_col1\" class=\"data row8 col1\" >5340</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row8_col2\" class=\"data row8 col2\" >0.441000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row9\" class=\"row_heading level0 row9\" >15</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row9_col0\" class=\"data row9 col0\" >Pagination</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row9_col1\" class=\"data row9 col1\" >5221</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row9_col2\" class=\"data row9 col2\" >0.431000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row10\" class=\"row_heading level0 row10\" >28</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row10_col0\" class=\"data row10 col0\" >Altmetric</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row10_col1\" class=\"data row10 col1\" >4996</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row10_col2\" class=\"data row10 col2\" >0.412000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row11\" class=\"row_heading level0 row11\" >23</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row11_col0\" class=\"data row11 col0\" >City of Research organization</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row11_col1\" class=\"data row11 col1\" >4835</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row11_col2\" class=\"data row11 col2\" >0.399000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row12\" class=\"row_heading level0 row12\" >24</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row12_col0\" class=\"data row12 col0\" >Country of Research organization</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row12_col1\" class=\"data row12 col1\" >4835</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row12_col2\" class=\"data row12 col2\" >0.399000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row13\" class=\"row_heading level0 row13\" >21</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row13_col0\" class=\"data row13 col0\" >Research Organizations - standardized</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row13_col1\" class=\"data row13 col1\" >4835</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row13_col2\" class=\"data row13 col2\" >0.399000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row14\" class=\"row_heading level0 row14\" >22</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row14_col0\" class=\"data row14 col0\" >GRID IDs</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row14_col1\" class=\"data row14 col1\" >4835</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row14_col2\" class=\"data row14 col2\" >0.399000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row15\" class=\"row_heading level0 row15\" >6</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row15_col0\" class=\"data row15 col0\" >Abstract</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row15_col1\" class=\"data row15 col1\" >4352</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row15_col2\" class=\"data row15 col2\" >0.359000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row16\" class=\"row_heading level0 row16\" >9</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row16_col0\" class=\"data row16 col0\" >Publisher</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row16_col1\" class=\"data row16 col1\" >1581</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row16_col2\" class=\"data row16 col2\" >0.130000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row17\" class=\"row_heading level0 row17\" >20</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row17_col0\" class=\"data row17 col0\" >Authors Affiliations</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row17_col1\" class=\"data row17 col1\" >721</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row17_col2\" class=\"data row17 col2\" >0.060000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row18_col0\" class=\"data row18 col0\" >Authors</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row18_col1\" class=\"data row18 col1\" >719</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row18_col2\" class=\"data row18 col2\" >0.059000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row19\" class=\"row_heading level0 row19\" >2</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row19_col0\" class=\"data row19 col0\" >DOI</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row19_col1\" class=\"data row19 col1\" >497</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row19_col2\" class=\"data row19 col2\" >0.041000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row20\" class=\"row_heading level0 row20\" >8</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row20_col0\" class=\"data row20 col0\" >Source UID</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row20_col1\" class=\"data row20 col1\" >459</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row20_col2\" class=\"data row20 col2\" >0.038000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row21\" class=\"row_heading level0 row21\" >7</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row21_col0\" class=\"data row21 col0\" >Source title</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row21_col1\" class=\"data row21 col1\" >459</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row21_col2\" class=\"data row21 col2\" >0.038000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row22\" class=\"row_heading level0 row22\" >27</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row22_col0\" class=\"data row22 col0\" >Times cited</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row22_col1\" class=\"data row22 col1\" >0</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row22_col2\" class=\"data row22 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row23\" class=\"row_heading level0 row23\" >0</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row23_col0\" class=\"data row23 col0\" >Date added</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row23_col1\" class=\"data row23 col1\" >0</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row23_col2\" class=\"data row23 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row24\" class=\"row_heading level0 row24\" >17</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row24_col0\" class=\"data row24 col0\" >Publication Type</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row24_col1\" class=\"data row24 col1\" >0</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row24_col2\" class=\"data row24 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row25\" class=\"row_heading level0 row25\" >16</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row25_col0\" class=\"data row25 col0\" >Open Access</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row25_col1\" class=\"data row25 col1\" >0</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row25_col2\" class=\"data row25 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row26\" class=\"row_heading level0 row26\" >1</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row26_col0\" class=\"data row26 col0\" >Publication ID</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row26_col1\" class=\"data row26 col1\" >0</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row26_col2\" class=\"data row26 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row27\" class=\"row_heading level0 row27\" >12</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row27_col0\" class=\"data row27 col0\" >PubYear</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row27_col1\" class=\"data row27 col1\" >0</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row27_col2\" class=\"data row27 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row28\" class=\"row_heading level0 row28\" >11</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row28_col0\" class=\"data row28 col0\" >Publication Date</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row28_col1\" class=\"data row28 col1\" >0</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row28_col2\" class=\"data row28 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row29\" class=\"row_heading level0 row29\" >5</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row29_col0\" class=\"data row29 col0\" >Title</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row29_col1\" class=\"data row29 col1\" >0</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row29_col2\" class=\"data row29 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row30_col0\" class=\"data row30 col0\" >Dimensions URL</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row30_col1\" class=\"data row30 col1\" >0</td>\n",
       "                        <td id=\"T_c9f2fa28_8315_11ea_8d71_0242ac110002row30_col2\" class=\"data row30 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f40fd60ecd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Read dataset from Dimensions ###\n",
    "df_pub = pd.read_csv('COVID19Publications.csv', sep=';')\n",
    "col = df_pub.columns\n",
    "check_missing(df_pub, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_info_csv(df_pub):\n",
    "    \n",
    "    ## Extract features we need from the original dataset ### \n",
    "    shortInfo_pub_df = df_pub[['Title', 'Source title', 'Publisher', 'Abstract','DOI', \\\n",
    "                               'Publication Type', 'Dimensions URL', 'Publication Date']]\n",
    "#     shortInfo_pub_df['DOI'] = 'https://doi.org/' + df_pub['DOI']\n",
    "\n",
    "    ### Check the paper langauge ###\n",
    "    lang_paper = []\n",
    "    for i in shortInfo_pub_df['Title']:\n",
    "        try:\n",
    "            lang_paper.append(detect(i))\n",
    "        except:\n",
    "            lang_paper.append(None)\n",
    "\n",
    "    shortInfo_pub_df['Language'] = lang_paper\n",
    "    \n",
    "    ### standardize the name of source title and publisher ###\n",
    "    new_source_title = []\n",
    "    new_publisher = []\n",
    "\n",
    "    for item in pub_df_2['Source title']:\n",
    "        try:\n",
    "            new_source_title.append(item.translate(str.maketrans('', '', string.punctuation)).replace(' ','_').lower())\n",
    "        except:\n",
    "            new_source_title.append(None)\n",
    "    for item in pub_df_2['Publisher']:\n",
    "        try:\n",
    "            new_publisher.append(item.translate(str.maketrans('', '', string.punctuation)).replace(' ','_').lower())\n",
    "        except:\n",
    "            new_publisher.append(None)\n",
    "\n",
    "    ### Save to a new data file ###\n",
    "    shortInfo_pub_df.to_csv('shortInfoPub.csv', index=None)\n",
    "\n",
    "    return shortInfo_pub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_paper_csv(df_pub):\n",
    "\n",
    "    ### Get authors list ###\n",
    "    author_list = []\n",
    "    unique_author_list = []\n",
    "\n",
    "    for author in df_pub['Authors']:\n",
    "        if type(author) == str:\n",
    "            author = author.replace(' ','')\n",
    "            splited_author = author.split(';')\n",
    "            author_list.append(splited_author)\n",
    "            for item in splited_author:\n",
    "                if item not in unique_author_list:\n",
    "                    unique_author_list.append(item)\n",
    "        else:\n",
    "            author_list.append([])\n",
    "\n",
    "\n",
    "    ### Remove unmeaningful author name ###\n",
    "    remove_name = [',', 'UN,']\n",
    "    for each_name in remove_name:\n",
    "        unique_author_list.remove(each_name)\n",
    "\n",
    "\n",
    "    ### Create Author-paper list ###\n",
    "    papers_each_author = []\n",
    "    for unique_author in unique_author_list:\n",
    "        for each_paper in range(0, len(author_list)):\n",
    "            if unique_author in author_list[each_paper]:\n",
    "                papers_each_author.append([unique_author, df_pub['Dimensions URL'][each_paper]])\n",
    "\n",
    "    papers_each_author_df = pd.DataFrame.from_records(papers_each_author)\n",
    "    papers_each_author_df.columns = ['Author', 'Dimensions URL']\n",
    "    \n",
    "    remove_punc_author = []\n",
    "    for item in au_pub['Author']:\n",
    "        remove_punc_author.append(item.translate(str.maketrans('', '', string.punctuation)).replace('ʼ',''))\n",
    "        \n",
    "    papers_each_author_df['Author_nopunc'] = remove_punc_author\n",
    "    papers_each_author_df.to_csv('AuthorsPub.csv', index=None)\n",
    "    \n",
    "    return papers_each_author_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract key words from title ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user -U nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://medium.com/@gaurav5430/using-nltk-for-lemmatizing-sentences-c1bfff963258\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tags: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "def get_extracted_keywords_from_title(shortInfo_pub_df):\n",
    "    \n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    stop_words.extend(['e.g', '’'])\n",
    "\n",
    "    title_filtered_sentence=[]\n",
    "\n",
    "    for item in range(0, len(shortInfo_pub_df['Title'])):\n",
    "        if shortInfo_pub_df['Language'][item] == 'en':\n",
    "            lemmatized_title = lemmatize_sentence(shortInfo_pub_df['Title'][item].lower())\n",
    "            tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+\\$[\\d\\.]+|\\S+')\n",
    "            tokens = tokenizer.tokenize(lemmatized_title)\n",
    "\n",
    "            tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "            each_title = []\n",
    "            for tag in tagged:\n",
    "                if tag[0] not in stop_words and tag[0] not in each_title:\n",
    "                    if ('NN' in tag[1]) or ('VB' in tag[1]) or ('JJ' in tag[1]):\n",
    "                        if (tag[0] not in string.punctuation) and (not tag[0].isdigit()):\n",
    "                            each_title.append(tag[0])\n",
    "            title_filtered_sentence.append(each_title)\n",
    "        else:\n",
    "            title_filtered_sentence.append([])\n",
    "    \n",
    "    \n",
    "    keywords_title_paper = []\n",
    "    for each_paper in range(0, len(title_filtered_sentence)):\n",
    "        for each_word in title_filtered_sentence[each_paper]:\n",
    "            keywords_title_paper.append([shortInfo_pub_df['Dimensions URL'][each_paper], each_word])\n",
    "            \n",
    "    return title_filtered_sentence, keywords_title_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use Gensim to find similar keywords ###\n",
    "def similar_keywords(title_filtered_sentence):\n",
    "    \n",
    "    model = gensim.models.Word2Vec(min_count=2, size=700, workers=5)\n",
    "    model.build_vocab(title_filtered_sentence)\n",
    "\n",
    "    corpus_count = model.corpus_count\n",
    "    model.train(title_filtered_sentence, total_examples = corpus_count, epochs = 1000)\n",
    "    \n",
    "    similar_keywords_list = []\n",
    "    for each in range(0, len(keywords_df)):\n",
    "        keyword = keywords_df['Keyword'][each]\n",
    "        try:\n",
    "            similar_keywords = model.wv.most_similar(keyword, topn=5)\n",
    "        except:\n",
    "            similar_keywords = []\n",
    "        for item in similar_keywords:   \n",
    "            similar_keywords_list.append([keywords_df['Dimensions URL'][each], keyword, item[0]])\n",
    "\n",
    "    return similar_keywords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    ### Read dataset from Dimensions ###\n",
    "    df_pub = pd.read_csv('COVID19Publications.csv', sep=';')\n",
    "    col = df_pub.columns\n",
    "    \n",
    "    ## Check missing values in the Dimensions dataset ###\n",
    "    check_missing(df_pub, col)\n",
    "    \n",
    "    ## Generate a new data file with key features ###\n",
    "    shortInfo_pub_df = paper_info_csv(df_pub)\n",
    "\n",
    "    ## Generate a author-paper data file ###\n",
    "    papers_each_author_df = author_paper_csv\n",
    "\n",
    "    ## Generate a paper-keywords (from title) data file ###\n",
    "    title_filtered_sentence, keywords_title_paper = get_extracted_keywords_from_title(shortInfo_pub_df)\n",
    "            \n",
    "    keywords_df = pd.DataFrame.from_records(keywords_title_paper)\n",
    "    keywords_df.columns = ['Dimensions URL', 'Keyword']\n",
    "    keywords_df.to_csv('keywordsPub.csv', index=None)\n",
    "\n",
    "    ## Get similar keywords and generate new keywords file ###\n",
    "    similar_keywords_list = similar_keywords(title_filtered_sentence)\n",
    "\n",
    "    similar_keywords_df = pd.DataFrame.from_records(similar_keywords_list)\n",
    "    similar_keywords_df.columns = ['Dimensions URL', 'Keyword', 'Similar_Keyword']\n",
    "    similar_keywords_df.to_csv('similarkeywordsPub.csv',index=None)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDF2Vec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create data structure for knowledge graph\n",
    "def addTriple(net, source, target, edge):\n",
    "    if source in net:\n",
    "        if  target in net[source]:\n",
    "            net[source][target].add(edge)\n",
    "        else:\n",
    "            net[source][target]= set([edge])\n",
    "    else:\n",
    "        net[source]={}\n",
    "        net[source][target] =set([edge])\n",
    "            \n",
    "def getLinks(net, source):\n",
    "    if source not in net:\n",
    "        return {}\n",
    "    return net[source]\n",
    "\n",
    "# Generate paths (entity->relation->entity) by radom walks\n",
    "def randomWalkUniform(triples, startNode, max_depth=5):\n",
    "    next_node =startNode\n",
    "    path = str(startNode)+'->'\n",
    "    for i in range(max_depth):\n",
    "        neighs = getLinks(triples,next_node)\n",
    "        #print (neighs)\n",
    "        if len(neighs) == 0: break\n",
    "        weights = []\n",
    "        queue = []\n",
    "        for neigh in neighs:\n",
    "            for edge in neighs[neigh]:\n",
    "                queue.append((edge,neigh))\n",
    "        edge, next_node = random.choice(queue)\n",
    "        path = path +str(edge)+'->'\n",
    "        path = path +str(next_node)+'->'\n",
    "    path =path.split('->')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the knowledge graph structure\n",
    "def preprocess(fname):\n",
    "    triples = {}\n",
    "\n",
    "    ent_counter = 0\n",
    "    rel_counter = 0\n",
    "    train_counter = 0\n",
    "\n",
    "    print (fname)\n",
    "    #gzfile= gzip.open(fname, mode='rt')\n",
    "\n",
    "    for line in csv.reader(open(fname), delimiter='\\t', quotechar='\"'):\n",
    "        #print (line)\n",
    "        h = line[0]\n",
    "        r = line[1]\n",
    "        t = line[2]\n",
    "        \n",
    "        train_counter +=1\n",
    "\n",
    "        addTriple(triples, h, t, r)\n",
    "        train_counter+=1\n",
    "    print ('Triple:',train_counter)\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query-result.tsv\n",
      "Triple: 342982\n",
      "12144\n"
     ]
    }
   ],
   "source": [
    "file = 'query-result.tsv'\n",
    "triples = preprocess(file)\n",
    "\n",
    "entities = list(triples.keys())\n",
    "vocabulary = entities\n",
    "print (len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do random walks on the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomNWalkUniform(triples, n, walks, path_depth):\n",
    "    path=[]\n",
    "    for k in range(walks):\n",
    "        walk = randomWalkUniform(triples, n, path_depth)\n",
    "        path.append(walk)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed to generate features: 00:00:13\n"
     ]
    }
   ],
   "source": [
    "walks = 100\n",
    "path_depth = 10\n",
    "\n",
    "start_time =time.time()\n",
    "sentences =[]\n",
    "for word in vocabulary:\n",
    "    sentences.extend( randomNWalkUniform(triples, word, walks, path_depth) )\n",
    "elapsed_time = time.time() - start_time\n",
    "print ('Time elapsed to generate features:',time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = gensim.models.Word2Vec(size=300, workers=5, window=5, sg=1)\n",
    "model1.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252631606, 488685800)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_count = model1.corpus_count\n",
    "model1.train(sentences, total_examples = corpus_count, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.wv.most_similar('<https://app.dimensions.ai/details/publication/pub.1126620775>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
