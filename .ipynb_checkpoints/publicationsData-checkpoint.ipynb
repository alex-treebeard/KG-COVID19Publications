{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "# !pip install langdetect\n",
    "import string\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "# !pip install -U gensim --user\n",
    "import gensim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random, time\n",
    "import gzip, os, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check if there is any missing value in the dataset ###\n",
    "def check_missing(df, col):\n",
    "    missing  = 0\n",
    "    misVariables = []\n",
    "    CheckNull = df.isnull().sum()\n",
    "    for var in range(0, len(CheckNull)):\n",
    "#         if CheckNull[var] != 0:\n",
    "        misVariables.append([col[var], CheckNull[var], round(CheckNull[var]/len(df),3)])\n",
    "        missing = missing + 1\n",
    "\n",
    "    if missing == 0:\n",
    "        print('Dataset is complete with no blanks.')\n",
    "    else:\n",
    "        print('Totally, %d features have missing values (blanks).' %missing)\n",
    "        df_misVariables = pd.DataFrame.from_records(misVariables)\n",
    "        df_misVariables.columns = ['Variable', 'Missing', 'Percentage (%)']\n",
    "        s = df_misVariables.sort_values(by=['Percentage (%)'], ascending=False).style.bar(subset=['Percentage (%)'], color='#d65f5f')\n",
    "        display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_info_csv(df_pub):\n",
    "    \n",
    "    ## Extract features we need from the original dataset ### \n",
    "    shortInfo_pub_df = df_pub[['Title', 'Source title', 'Publisher', 'Abstract','DOI', \\\n",
    "                               'Publication Type', 'Dimensions URL', 'Publication Date']]\n",
    "#     shortInfo_pub_df['DOI'] = 'https://doi.org/' + df_pub['DOI']\n",
    "\n",
    "    ### Check the paper langauge ###\n",
    "    lang_paper = []\n",
    "    for i in shortInfo_pub_df['Title']:\n",
    "        try:\n",
    "            lang_paper.append(detect(i))\n",
    "        except:\n",
    "            lang_paper.append(None)\n",
    "\n",
    "    shortInfo_pub_df['Language'] = lang_paper\n",
    "    \n",
    "    ### standardize the name of source title and publisher ###\n",
    "    new_source_title = []\n",
    "    new_publisher = []\n",
    "\n",
    "    for item in pub_df_2['Source title']:\n",
    "        try:\n",
    "            new_source_title.append(item.translate(str.maketrans('', '', string.punctuation)).replace(' ','_').lower())\n",
    "        except:\n",
    "            new_source_title.append(None)\n",
    "    for item in pub_df_2['Publisher']:\n",
    "        try:\n",
    "            new_publisher.append(item.translate(str.maketrans('', '', string.punctuation)).replace(' ','_').lower())\n",
    "        except:\n",
    "            new_publisher.append(None)\n",
    "\n",
    "    ### Save to a new data file ###\n",
    "    shortInfo_pub_df.to_csv('shortInfoPub.csv', index=None)\n",
    "\n",
    "    return shortInfo_pub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_paper_csv(df_pub):\n",
    "\n",
    "    ### Get authors list ###\n",
    "    author_list = []\n",
    "    unique_author_list = []\n",
    "\n",
    "    for author in df_pub['Authors']:\n",
    "        if type(author) == str:\n",
    "            author = author.replace(' ','')\n",
    "            splited_author = author.split(';')\n",
    "            author_list.append(splited_author)\n",
    "            for item in splited_author:\n",
    "                if item not in unique_author_list:\n",
    "                    unique_author_list.append(item)\n",
    "        else:\n",
    "            author_list.append([])\n",
    "\n",
    "\n",
    "    ### Remove unmeaningful author name ###\n",
    "    remove_name = [',', 'UN,']\n",
    "    for each_name in remove_name:\n",
    "        unique_author_list.remove(each_name)\n",
    "\n",
    "\n",
    "    ### Create Author-paper list ###\n",
    "    papers_each_author = []\n",
    "    for unique_author in unique_author_list:\n",
    "        for each_paper in range(0, len(author_list)):\n",
    "            if unique_author in author_list[each_paper]:\n",
    "                papers_each_author.append([unique_author, df_pub['Dimensions URL'][each_paper]])\n",
    "\n",
    "    papers_each_author_df = pd.DataFrame.from_records(papers_each_author)\n",
    "    papers_each_author_df.columns = ['Author', 'Dimensions URL']\n",
    "    \n",
    "    remove_punc_author = []\n",
    "    for item in au_pub['Author']:\n",
    "        remove_punc_author.append(item.translate(str.maketrans('', '', string.punctuation)).replace('ʼ',''))\n",
    "        \n",
    "    papers_each_author_df['Author_nopunc'] = remove_punc_author\n",
    "    papers_each_author_df.to_csv('AuthorsPub.csv', index=None)\n",
    "    \n",
    "    return papers_each_author_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract key words from title ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user -U nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://medium.com/@gaurav5430/using-nltk-for-lemmatizing-sentences-c1bfff963258\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tags: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "def get_extracted_keywords_from_title(shortInfo_pub_df):\n",
    "    \n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    stop_words.extend(['e.g', '’'])\n",
    "\n",
    "    title_filtered_sentence=[]\n",
    "\n",
    "    for item in range(0, len(shortInfo_pub_df['Title'])):\n",
    "        if shortInfo_pub_df['Language'][item] == 'en':\n",
    "            lemmatized_title = lemmatize_sentence(shortInfo_pub_df['Title'][item].lower())\n",
    "            tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+\\$[\\d\\.]+|\\S+')\n",
    "            tokens = tokenizer.tokenize(lemmatized_title)\n",
    "\n",
    "            tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "            each_title = []\n",
    "            for tag in tagged:\n",
    "                if tag[0] not in stop_words and tag[0] not in each_title:\n",
    "                    if ('NN' in tag[1]) or ('VB' in tag[1]) or ('JJ' in tag[1]):\n",
    "                        if (tag[0] not in string.punctuation) and (not tag[0].isdigit()) and (len(tag[0])>2):\n",
    "                            each_title.append(tag[0])\n",
    "            title_filtered_sentence.append(each_title)\n",
    "        else:\n",
    "            title_filtered_sentence.append([])\n",
    "    \n",
    "    \n",
    "    keywords_title_paper = []\n",
    "    for each_paper in range(0, len(title_filtered_sentence)):\n",
    "        for each_word in title_filtered_sentence[each_paper]:\n",
    "            keywords_title_paper.append([shortInfo_pub_df['Dimensions URL'][each_paper], each_word])\n",
    "            \n",
    "    return title_filtered_sentence, keywords_title_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use Gensim to find similar keywords ###\n",
    "def similar_keywords(title_filtered_sentence):\n",
    "    \n",
    "    model = gensim.models.Word2Vec(min_count=2, size=700, workers=5)\n",
    "    model.build_vocab(title_filtered_sentence)\n",
    "\n",
    "    corpus_count = model.corpus_count\n",
    "    model.train(title_filtered_sentence, total_examples = corpus_count, epochs = 1000)\n",
    "    \n",
    "    similar_keywords_list = []\n",
    "    for each in range(0, len(keywords_df)):\n",
    "        keyword = keywords_df['Keyword'][each]\n",
    "        try:\n",
    "            similar_keywords = model.wv.most_similar(keyword, topn=5)\n",
    "        except:\n",
    "            similar_keywords = []\n",
    "        for item in similar_keywords:   \n",
    "            similar_keywords_list.append([keywords_df['Dimensions URL'][each], keyword, item[0]])\n",
    "\n",
    "    return similar_keywords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    ### Read dataset from Dimensions ###\n",
    "    df_pub = pd.read_csv('COVID19Publications.csv', sep=';')\n",
    "    col = df_pub.columns\n",
    "    \n",
    "    ## Check missing values in the Dimensions dataset ###\n",
    "#     check_missing(df_pub, col)\n",
    "    \n",
    "    ## Generate a new data file with key features ###\n",
    "    shortInfo_pub_df = paper_info_csv(df_pub)\n",
    "\n",
    "    ## Generate a author-paper data file ###\n",
    "    papers_each_author_df = author_paper_csv\n",
    "\n",
    "    ## Generate a paper-keywords (from title) data file ###\n",
    "    title_filtered_sentence, keywords_title_paper = get_extracted_keywords_from_title(shortInfo_pub_df)\n",
    "            \n",
    "    keywords_df = pd.DataFrame.from_records(keywords_title_paper)\n",
    "    keywords_df.columns = ['Dimensions URL', 'Keyword']\n",
    "    keywords_df.to_csv('keywordsPub.csv', index=None)\n",
    "\n",
    "    ## Get similar keywords and generate new keywords file ###\n",
    "#     similar_keywords_list = similar_keywords(title_filtered_sentence)\n",
    "\n",
    "#     similar_keywords_df = pd.DataFrame.from_records(similar_keywords_list)\n",
    "#     similar_keywords_df.columns = ['Dimensions URL', 'Keyword', 'Similar_Keyword']\n",
    "#     similar_keywords_df.to_csv('similarkeywordsPub.csv',index=None)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortInfo_pub_df = pd.read_csv('extracted_datafiles/shortInfoPub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_filtered_sentence, keywords_title_paper = get_extracted_keywords_from_title(shortInfo_pub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use\n",
      "new\n",
      "era\n",
      "use\n",
      "old\n",
      "new\n",
      "hiv\n",
      "pcr\n",
      "era\n",
      "new\n",
      "use\n",
      "dsm\n",
      "due\n",
      "igm\n",
      "new\n",
      "rna\n",
      "gap\n",
      "n95\n",
      "law\n",
      "use\n",
      "ask\n",
      "sex\n",
      "age\n",
      "use\n",
      "bcg\n",
      "sga\n",
      "air\n",
      "con\n",
      "vsv\n",
      "use\n",
      "use\n",
      "rho\n",
      "air\n",
      "old\n",
      "new\n",
      "gap\n",
      "rmb\n",
      "use\n",
      "aim\n",
      "bug\n",
      "era\n",
      "use\n",
      "use\n",
      "old\n",
      "ibd\n",
      "ill\n",
      "age\n",
      "era\n",
      "due\n",
      "co2\n",
      "emg\n",
      "bag\n",
      "sea\n",
      "use\n",
      "set\n",
      "use\n",
      "war\n",
      "run\n",
      "ill\n",
      "use\n",
      "era\n",
      "rna\n",
      "dr.\n",
      "due\n",
      "no2\n",
      "new\n",
      "ada\n",
      "cdc\n",
      "use\n",
      "icu\n",
      "day\n",
      "usa\n",
      "ark\n",
      "nhs\n",
      "pcr\n",
      "ren\n",
      "new\n",
      "age\n",
      "log\n",
      "age\n",
      "rna\n",
      "tax\n",
      "act\n",
      "era\n",
      "cdc\n",
      "age\n",
      "qtc\n",
      "lie\n",
      "-19\n",
      "use\n",
      "irs\n",
      "map\n",
      "new\n",
      "art\n",
      "use\n",
      "old\n",
      "tip\n",
      "aid\n",
      "use\n",
      "use\n",
      "get\n",
      "pet\n",
      "low\n",
      "tip\n",
      "age\n",
      "ill\n",
      "era\n",
      "nhs\n",
      "nhs\n",
      "old\n",
      "get\n",
      "die\n",
      "way\n",
      "end\n",
      "hcq\n",
      "use\n",
      "end\n",
      "age\n",
      "alp\n",
      "ace\n",
      "arb\n",
      "dna\n",
      "ras\n",
      "use\n",
      "due\n",
      "day\n",
      "key\n",
      "u.s\n",
      "del\n",
      "bcg\n",
      "map\n",
      "day\n",
      "use\n",
      "dna\n",
      "ras\n",
      "mdt\n",
      "use\n",
      "gdp\n",
      "key\n",
      "map\n",
      "use\n",
      "new\n",
      "use\n",
      "use\n",
      "law\n",
      "use\n",
      "use\n",
      "eat\n",
      "bat\n",
      "web\n",
      "use\n",
      "old\n",
      "gdc\n",
      "art\n",
      "anz\n",
      "use\n",
      "rat\n",
      "map\n",
      "use\n",
      "use\n",
      "new\n",
      "set\n",
      "gym\n",
      "tip\n",
      "new\n",
      "new\n",
      "use\n",
      "pda\n",
      "iii\n",
      "san\n",
      "bad\n",
      "pci\n",
      "use\n",
      "apa\n",
      "apa\n",
      "g20\n",
      "nas\n",
      "fda\n",
      "use\n",
      "use\n",
      "cdc\n",
      "due\n",
      "hpv\n",
      "old\n",
      "ill\n",
      "eye\n",
      "uic\n",
      "tie\n",
      "bda\n",
      "new\n",
      "jaw\n",
      "era\n",
      "end\n",
      "use\n",
      "icu\n",
      "use\n",
      "law\n",
      "due\n",
      "run\n",
      "rbd\n",
      "war\n",
      "ocd\n",
      "air\n",
      "use\n",
      "fix\n",
      "use\n",
      "era\n",
      "mmt\n",
      "hiv\n",
      "new\n",
      "use\n",
      "pay\n",
      "era\n",
      "era\n",
      "ill\n",
      "new\n",
      "die\n",
      "air\n",
      "bed\n",
      "pcr\n",
      "mix\n",
      "icu\n",
      "cat\n",
      "dog\n",
      "age\n",
      "use\n",
      "niv\n",
      "day\n",
      "bcg\n",
      "new\n",
      "top\n",
      "al.\n",
      "top\n",
      "rsv\n",
      "aim\n",
      "ros\n",
      "bat\n",
      "niv\n",
      "new\n",
      "air\n",
      "get\n",
      "art\n",
      "ill\n",
      "icu\n",
      "era\n",
      "old\n",
      "low\n",
      "sud\n",
      "cut\n",
      "fit\n",
      "rna\n",
      "new\n",
      "usa\n",
      "new\n",
      "law\n",
      "ill\n",
      "new\n",
      "sir\n",
      "gdp\n",
      "use\n",
      "oil\n",
      "age\n",
      "u.s\n",
      "use\n",
      "pei\n",
      "use\n",
      "key\n",
      "due\n",
      "use\n",
      "n95\n",
      "oil\n",
      "new\n",
      "pap\n",
      "use\n",
      "use\n",
      "key\n",
      "day\n",
      "age\n",
      "ppe\n",
      "pro\n",
      "con\n",
      "shi\n",
      "gan\n",
      "old\n",
      "get\n",
      "new\n",
      "era\n",
      "app\n",
      "pcr\n",
      "age\n",
      "hr1\n",
      "use\n",
      "due\n",
      "icu\n",
      "use\n",
      "use\n",
      "day\n",
      "due\n",
      "igm\n",
      "igg\n",
      "nhs\n",
      "phd\n",
      "pcr\n",
      "igm\n",
      "igg\n",
      "day\n",
      "1-7\n",
      "hcv\n",
      "age\n",
      "gap\n",
      "new\n",
      "use\n",
      "cdc\n",
      "bcg\n",
      "map\n",
      "cat\n",
      "dog\n",
      "low\n",
      "pet\n",
      "use\n",
      "rna\n",
      "era\n",
      "nhs\n",
      "cdc\n",
      "cdc\n",
      "dry\n",
      "due\n",
      "qtc\n",
      "bed\n",
      "use\n",
      "ipc\n",
      "n95\n",
      "use\n",
      "use\n",
      "era\n",
      "set\n",
      "sdg\n",
      "new\n",
      "old\n",
      "ill\n",
      "sub\n",
      "saa\n",
      "n95\n",
      "due\n",
      "hiv\n",
      "fda\n",
      "cdc\n",
      "art\n",
      "red\n",
      "usa\n",
      "cdc\n",
      "rna\n",
      "rtl\n",
      "bcg\n",
      "era\n",
      "cop\n",
      "use\n",
      "die\n",
      "usa\n",
      "cdc\n",
      "eau\n",
      "new\n",
      "old\n",
      "dot\n",
      "gas\n",
      "new\n",
      "use\n",
      "al.\n",
      "old\n",
      "mco\n",
      "ppe\n",
      "use\n",
      "ppe\n",
      "air\n",
      "low\n",
      "u.s\n",
      "tip\n",
      "bat\n",
      "hop\n",
      "hiv\n",
      "use\n",
      "use\n",
      "set\n",
      "kit\n",
      "day\n",
      "sub\n",
      "pcr\n",
      "iii\n",
      "ill\n",
      "use\n",
      "man\n",
      "rna\n",
      "new\n",
      "new\n",
      "cdc\n",
      "ecg\n",
      "pep\n",
      "arf\n",
      "map\n",
      "use\n",
      "new\n",
      "kit\n",
      "use\n",
      "old\n",
      "use\n",
      "aid\n",
      "san\n",
      "new\n",
      "use\n",
      "ncp\n",
      "use\n",
      "new\n",
      "low\n",
      "use\n",
      "cat\n",
      "era\n",
      "pro\n",
      "due\n",
      "use\n",
      "mri\n",
      "aid\n",
      "use\n",
      "cry\n",
      "key\n",
      "age\n",
      "use\n",
      "use\n",
      "age\n",
      "use\n",
      "gap\n",
      "pcr\n",
      "cdc\n",
      "use\n",
      "hiv\n",
      "usa\n",
      "law\n",
      "hiv\n",
      "key\n",
      "use\n",
      "age\n",
      "eat\n",
      "due\n",
      "ear\n",
      "n95\n",
      "ado\n",
      "era\n",
      "big\n",
      "bcg\n",
      "use\n",
      "due\n",
      "low\n",
      "air\n",
      "ill\n",
      "pcr\n",
      "use\n",
      "key\n",
      "icu\n",
      "sac\n",
      "due\n",
      "use\n",
      "bat\n",
      "new\n",
      "old\n",
      "nhs\n",
      "air\n",
      "new\n",
      "icu\n",
      "gap\n",
      "use\n",
      "use\n",
      "hiv\n",
      "und\n",
      "day\n",
      "new\n",
      "day\n",
      "aid\n",
      "tpa\n",
      "low\n",
      "say\n",
      "due\n",
      "dna\n",
      "flu\n",
      "use\n",
      "ags\n",
      "era\n",
      "add\n",
      "new\n",
      "new\n",
      "old\n",
      "new\n",
      "use\n",
      "run\n",
      "hot\n",
      "dna\n",
      "era\n",
      "use\n",
      "app\n",
      "new\n",
      "use\n",
      "new\n",
      "new\n",
      "-19\n",
      "way\n",
      "bcg\n",
      "new\n",
      "ill\n",
      "air\n",
      "icu\n",
      "old\n",
      "cop\n",
      "cov\n",
      "war\n",
      "end\n",
      "men\n",
      "k12\n",
      "era\n",
      "nyc\n",
      "blv\n",
      "air\n",
      "tie\n",
      "day\n",
      "kit\n",
      "use\n",
      "era\n",
      "new\n",
      "use\n",
      "use\n",
      "sir\n",
      "ode\n",
      "use\n",
      "use\n",
      "use\n",
      "i3e\n",
      "use\n",
      "bed\n",
      "gdp\n",
      "see\n",
      "use\n",
      "low\n",
      "air\n",
      "eye\n",
      "use\n",
      "use\n",
      "dx®\n",
      "er+\n",
      "use\n",
      "bcg\n",
      "hps\n",
      "use\n",
      "com\n",
      "ppe\n",
      "bcg\n",
      "use\n",
      "bcg\n",
      "bme\n",
      "rip\n",
      "usa\n",
      "use\n",
      "cdc\n",
      "cdc\n",
      "ifn\n",
      "use\n",
      "i3e\n",
      "use\n",
      "eye\n",
      "ase\n",
      "low\n",
      "get\n",
      "eat\n",
      "day\n",
      "use\n",
      "law\n",
      "use\n",
      "dis\n",
      "era\n",
      "cfr\n",
      "use\n",
      "ppe\n",
      "new\n",
      "use\n",
      "law\n",
      "use\n",
      "use\n",
      "ill\n",
      "acc\n",
      "use\n",
      "war\n",
      "shi\n",
      "smi\n",
      "age\n",
      "app\n",
      "use\n",
      "use\n",
      "due\n",
      "new\n",
      "hiv\n",
      "map\n",
      "new\n",
      "use\n",
      "due\n",
      "job\n",
      "san\n",
      "hot\n",
      "end\n",
      "new\n",
      "top\n",
      "age\n",
      "new\n",
      "hub\n",
      "eea\n",
      "see\n",
      "arb\n",
      "ill\n",
      "era\n",
      "ill\n",
      "set\n",
      "way\n",
      "rna\n",
      "mhv\n",
      "use\n",
      "rtx\n",
      "new\n",
      "dna\n",
      "cov\n",
      "rna\n",
      "fda\n",
      "sun\n",
      "acc\n",
      "use\n",
      "key\n",
      "use\n",
      "mja\n",
      "ant\n",
      "due\n",
      "rna\n",
      "pcr\n",
      "hiv\n",
      "flu\n",
      "act\n",
      "ade\n",
      "rna\n",
      "bda\n",
      "war\n",
      "win\n",
      "fix\n",
      "air\n",
      "new\n",
      "age\n",
      "use\n",
      "odd\n",
      "isg\n",
      "aim\n",
      "jth\n",
      "due\n",
      "eye\n",
      "era\n",
      "ace\n",
      "ski\n",
      "icu\n",
      "era\n",
      "let\n",
      "use\n",
      "new\n",
      "new\n",
      "n95\n",
      "ent\n",
      "use\n",
      "due\n",
      "phe\n",
      "ppe\n",
      "day\n",
      "end\n",
      "-19\n",
      "hit\n",
      "low\n",
      "old\n",
      "age\n",
      "sex\n",
      "owe\n",
      "use\n",
      "icu\n",
      "due\n",
      "cat\n",
      "man\n",
      "new\n",
      "new\n",
      "icu\n",
      "han\n",
      "use\n",
      "ili\n",
      "ill\n",
      "new\n",
      "non\n",
      "day\n",
      "rna\n",
      "cdc\n",
      "rna\n",
      "due\n",
      "new\n",
      "use\n",
      "map\n",
      "-19\n",
      "fda\n",
      "age\n",
      "say\n",
      "fix\n",
      "bva\n",
      "low\n",
      "cop\n",
      "usa\n",
      "cdc\n",
      "cdc\n",
      "use\n",
      "web\n",
      "due\n",
      "net\n",
      "use\n",
      "ill\n",
      "bva\n",
      "new\n",
      "isg\n",
      "cvs\n",
      "cut\n",
      "ask\n",
      "let\n",
      "use\n",
      "new\n",
      "old\n",
      "web\n",
      "oil\n",
      "get\n",
      "net\n",
      "1-7\n",
      "age\n",
      "use\n",
      "rna\n",
      "use\n",
      "new\n",
      "use\n",
      "use\n",
      "big\n",
      "hev\n",
      "n95\n",
      "n99\n",
      "use\n",
      "new\n",
      "aim\n",
      "bed\n",
      "era\n",
      "ask\n",
      "new\n",
      "rna\n",
      "new\n",
      "age\n",
      "act\n",
      "day\n",
      "acs\n",
      "act\n",
      "cfr\n",
      "era\n",
      "new\n",
      "set\n",
      "hiv\n",
      "old\n",
      "ama\n",
      "mat\n",
      "dea\n",
      "era\n",
      "fda\n",
      "bad\n",
      "arm\n",
      "use\n",
      "use\n",
      "ase\n",
      "oas\n",
      "end\n",
      "sex\n",
      "new\n",
      "use\n",
      "usa\n",
      "low\n",
      "use\n",
      "age\n",
      "use\n",
      "n95\n",
      "law\n",
      "gsh\n",
      "use\n",
      "pcr\n",
      "new\n",
      "air\n",
      "cdc\n",
      "tip\n",
      "g20\n",
      "fun\n",
      "lab\n",
      "age\n",
      "ill\n",
      "use\n",
      "sex\n",
      "war\n",
      "cop\n",
      "use\n",
      "use\n",
      "art\n",
      "era\n",
      "rna\n",
      "bay\n",
      "use\n",
      "ect\n",
      "men\n",
      "use\n",
      "day\n",
      "use\n",
      "key\n",
      "ibd\n",
      "cd8\n",
      "cd4\n",
      "key\n",
      "ibd\n",
      "ect\n",
      "bnp\n",
      "use\n",
      "icu\n",
      "day\n",
      "san\n",
      "wbc\n",
      "lym\n",
      "cdc\n",
      "era\n",
      "tip\n",
      "key\n",
      "act\n",
      "set\n",
      "new\n",
      "use\n",
      "web\n",
      "rat\n",
      "act\n",
      "wbg\n",
      "low\n",
      "use\n",
      "arm\n",
      "low\n",
      "due\n",
      "key\n",
      "cdc\n",
      "g20\n",
      "new\n",
      "key\n",
      "nse\n",
      "key\n",
      "day\n",
      "imf\n",
      "fpm\n",
      "flu\n",
      "key\n",
      "use\n",
      "non\n",
      "big\n",
      "use\n",
      "oil\n",
      "use\n",
      "new\n",
      "rna\n",
      "air\n",
      "tsp\n",
      "fda\n",
      "app\n",
      "ten\n",
      "tip\n",
      "war\n",
      "low\n",
      "tap\n",
      "rna\n",
      "put\n",
      "map\n",
      "ppe\n",
      "use\n",
      "fda\n",
      "map\n",
      "fda\n",
      "use\n",
      "rna\n",
      "use\n",
      "air\n",
      "tsp\n",
      "cop\n",
      "ill\n",
      "age\n",
      "day\n",
      "way\n",
      "era\n",
      "way\n",
      "ibd\n",
      "age\n",
      "use\n",
      "old\n",
      "use\n",
      "new\n",
      "nnf\n",
      "iap\n",
      "era\n",
      "low\n",
      "ion\n",
      "sir\n",
      "use\n",
      "use\n",
      "r_0\n",
      "cir\n",
      "use\n",
      "use\n",
      "air\n",
      "cap\n",
      "nhs\n",
      "quo\n",
      "new\n",
      "dr.\n",
      "cdc\n",
      "due\n",
      "era\n",
      "day\n",
      "cdc\n",
      "cop\n",
      "age\n",
      "day\n",
      "icu\n",
      "air\n",
      "foe\n",
      "age\n",
      "mic\n",
      "aid\n",
      "cdc\n",
      "old\n",
      "hiv\n",
      "aid\n",
      "air\n",
      "age\n",
      "arm\n",
      "use\n",
      "igm\n",
      "use\n",
      "say\n",
      "sir\n",
      "med\n",
      "e20\n",
      "use\n",
      "new\n",
      "pas\n",
      "day\n",
      "kid\n",
      "use\n",
      "sir\n",
      "old\n",
      "use\n",
      "eye\n",
      "con\n",
      "ten\n",
      "new\n",
      "cop\n",
      "tin\n",
      "kvp\n",
      "low\n",
      "law\n",
      "use\n",
      "see\n",
      "age\n",
      "dr.\n",
      "day\n",
      "arm\n",
      "new\n",
      "use\n",
      "air\n",
      "due\n",
      "use\n",
      "tip\n",
      "hla\n",
      "use\n",
      "ice\n",
      "day\n",
      "get\n",
      "get\n",
      "new\n",
      "low\n",
      "rna\n",
      "mmr\n",
      "ace\n",
      "use\n",
      "big\n",
      "cop\n",
      "nhs\n",
      "rna\n",
      "non\n",
      "nsp\n",
      "rna\n",
      "non\n",
      "nsp\n",
      "use\n",
      "use\n",
      "ace\n",
      "use\n",
      "use\n",
      "new\n",
      "app\n",
      "new\n",
      "end\n",
      "usa\n",
      "map\n",
      "use\n",
      "use\n",
      "big\n",
      "run\n",
      "day\n",
      "hiv\n",
      "use\n",
      "use\n",
      "'we\n",
      "ent\n",
      "'re\n",
      "ill\n",
      "new\n",
      "sex\n",
      "map\n",
      "use\n",
      "law\n",
      "pay\n",
      "day\n",
      "eye\n",
      "way\n",
      "old\n",
      "old\n",
      "med\n",
      "fda\n",
      "nda\n",
      "ten\n",
      "ihr\n",
      "pay\n",
      "tcm\n",
      "tcv\n",
      "ash\n",
      "tap\n",
      "way\n",
      "cat\n",
      "dog\n",
      "era\n",
      "aid\n",
      "ill\n",
      "red\n",
      "wen\n",
      "doi\n",
      "sap\n",
      "lab\n",
      "use\n",
      "n95\n",
      "usa\n",
      "end\n",
      "old\n",
      "bat\n",
      "new\n",
      "usa\n",
      "way\n",
      "eat\n",
      "era\n",
      "mri\n",
      "tip\n",
      "pcr\n",
      "act\n",
      "low\n",
      "new\n",
      "abc\n",
      "era\n",
      "use\n",
      "use\n",
      "dna\n",
      "era\n",
      "use\n",
      "cdc\n",
      "day\n",
      "rna\n",
      "cdc\n",
      "cdc\n",
      "rna\n",
      "ace\n",
      "arb\n",
      "use\n",
      "ark\n",
      "cpr\n",
      "run\n",
      "new\n",
      "rna\n",
      "lie\n",
      "cnn\n",
      "pcr\n",
      "age\n",
      "jan\n",
      "ppe\n",
      "bma\n",
      "new\n",
      "let\n",
      "get\n",
      "cod\n",
      "ill\n",
      "eye\n",
      "new\n",
      "rna\n",
      "use\n",
      "pcr\n",
      "use\n",
      "act\n",
      "use\n",
      "due\n",
      "bed\n",
      "ema\n",
      "use\n",
      "new\n",
      "key\n",
      "new\n",
      "get\n",
      "ppe\n",
      "use\n",
      "cdc\n",
      "cns\n",
      "ncp\n",
      "oil\n",
      "pay\n",
      "cop\n",
      "war\n",
      "big\n",
      "lab\n",
      "new\n",
      "old\n",
      "age\n",
      "usa\n",
      "act\n",
      "old\n",
      "new\n",
      "ill\n",
      "new\n",
      "use\n",
      "mrt\n",
      "sid\n",
      "npi\n",
      "los\n",
      "flu\n",
      "ppe\n",
      "map\n",
      "‐19\n",
      "aid\n",
      "law\n",
      "age\n",
      "get\n",
      "eye\n",
      "top\n",
      "use\n",
      "hoc\n",
      "use\n",
      "rna\n",
      "due\n",
      "war\n",
      "app\n",
      "run\n",
      "use\n",
      "use\n",
      "new\n",
      "old\n",
      "cov\n",
      "new\n",
      "oil\n",
      "use\n",
      "ace\n",
      "arb\n",
      "due\n",
      "use\n",
      "sex\n",
      "age\n",
      "sex\n",
      "use\n",
      "isa\n",
      "new\n",
      "use\n",
      "war\n",
      "ill\n",
      "use\n",
      "era\n",
      "big\n",
      "vet\n",
      "cfr\n",
      "net\n",
      "use\n",
      "kit\n",
      "ill\n",
      "ban\n",
      "dis\n",
      "way\n",
      "art\n",
      "day\n",
      "apa\n",
      "get\n",
      "neh\n",
      "use\n",
      "app\n",
      "set\n",
      "ill\n",
      "use\n",
      "ecg\n",
      "old\n",
      "new\n",
      "csc\n",
      "pig\n",
      "ibd\n",
      "thy\n",
      "neh\n",
      "see\n",
      "vet\n",
      "say\n",
      "usa\n",
      "ill\n",
      "fat\n",
      "hfd\n",
      "law\n",
      "air\n",
      "day\n",
      "igg\n",
      "gps\n",
      "key\n",
      "aye\n",
      "set\n",
      "new\n",
      "use\n",
      "bma\n",
      "rna\n",
      "rna\n",
      "law\n",
      "era\n",
      "new\n",
      "flu\n",
      "u.s\n",
      "use\n",
      "new\n",
      "bcg\n",
      "air\n",
      "new\n",
      "fy1\n",
      "apa\n",
      "use\n",
      "mvm\n",
      "oud\n",
      "hiv\n",
      "n95\n",
      "dis\n",
      "aca\n",
      "gay\n",
      "men\n",
      "'re\n",
      "ccd\n",
      "use\n",
      "sso\n",
      "bed\n",
      "big\n",
      "rna\n",
      "igm\n",
      "nhs\n",
      "rna\n",
      "map\n",
      "bdj\n",
      "igm\n",
      "use\n",
      "eye\n",
      "rag\n",
      "ppe\n",
      "rub\n",
      "eye\n",
      "key\n",
      "use\n",
      "put\n",
      "ion\n",
      "use\n",
      "use\n",
      "ten\n",
      "cdc\n",
      "new\n",
      "way\n",
      "use\n",
      "fda\n",
      "key\n",
      "low\n",
      "hip\n",
      "nhs\n",
      "tcm\n",
      "lab\n",
      "key\n",
      "icu\n",
      "old\n",
      "age\n",
      "day\n",
      "die\n",
      "day\n",
      "new\n",
      "old\n",
      "age\n",
      "use\n",
      "air\n",
      "old\n",
      "cdc\n",
      "ppe\n",
      "key\n",
      "ion\n",
      "ban\n",
      "new\n",
      "new\n",
      "new\n",
      "low\n",
      "use\n",
      "new\n",
      "cut\n",
      "day\n",
      "eye\n",
      "new\n",
      "ill\n",
      "new\n",
      "ill\n",
      "gas\n",
      "fee\n",
      "dog\n",
      "law\n",
      "ban\n",
      "key\n",
      "mxb\n",
      "tip\n",
      "pgt\n",
      "tmd\n",
      "aid\n",
      "fda\n",
      "use\n",
      "ill\n",
      "fix\n",
      "die\n",
      "bed\n",
      "sea\n",
      "way\n",
      "lay\n",
      "use\n",
      "cdc\n",
      "rat\n",
      "map\n",
      "nsf\n",
      "hip\n",
      "lie\n",
      "new\n",
      "bat\n",
      "die\n",
      "sir\n",
      "sir\n",
      "law\n",
      "use\n",
      "new\n",
      "use\n",
      "map\n",
      "los\n",
      "sir\n",
      "sir\n",
      "ill\n",
      "run\n",
      "use\n",
      "new\n",
      "dis\n",
      "-19\n",
      "law\n",
      "law\n",
      "old\n",
      "new\n",
      "new\n",
      "fit\n",
      "n95\n",
      "usa\n",
      "msk\n",
      "new\n",
      "rna\n",
      "arc\n",
      "rna\n",
      "new\n",
      "use\n",
      "use\n",
      "use\n",
      "air\n",
      "use\n",
      "oil\n",
      "new\n",
      "old\n",
      "use\n",
      "air\n",
      "see\n",
      "end\n",
      "map\n",
      "use\n",
      "usa\n",
      "map\n",
      "elm\n",
      "rna\n",
      "use\n",
      "ill\n",
      "use\n",
      "act\n",
      "new\n",
      "law\n",
      "int\n",
      "ibd\n",
      "new\n",
      "fda\n",
      "dog\n",
      "lqf\n",
      "say\n",
      "use\n",
      "rna\n",
      "saa\n",
      "use\n",
      "jan\n",
      "use\n",
      "use\n",
      "dog\n",
      "dna\n",
      "icu\n",
      "age\n",
      "use\n",
      "nhs\n",
      "say\n",
      "ihr\n",
      "eir\n",
      "day\n",
      "key\n",
      "aid\n",
      "icu\n",
      "rna\n",
      "tip\n",
      "low\n",
      "new\n",
      "key\n",
      "rna\n",
      "key\n",
      "key\n",
      "say\n",
      "bma\n",
      "new\n",
      "o2o\n",
      "rna\n",
      "lqf\n",
      "use\n",
      "hcv\n",
      "use\n",
      "rna\n",
      "gdp\n",
      "map\n",
      "ivf\n",
      "ill\n",
      "g/m\n",
      "era\n",
      "use\n",
      "new\n",
      "icu\n",
      "acp\n",
      "cop\n",
      "use\n",
      "use\n",
      "ade\n",
      "bar\n",
      "cop\n",
      "new\n",
      "old\n",
      "spe\n",
      "new\n",
      "put\n",
      "key\n",
      "dos\n",
      "new\n",
      "ask\n",
      "new\n",
      "old\n",
      "nhs\n",
      "say\n",
      "aeg\n",
      "use\n",
      "cdc\n",
      "use\n",
      "use\n",
      "icu\n",
      "sir\n",
      "mvm\n",
      "use\n",
      "use\n",
      "use\n",
      "sir\n",
      "ape\n",
      "use\n",
      "air\n",
      "use\n",
      "gmc\n",
      "use\n",
      "ban\n",
      "ban\n",
      "age\n",
      "key\n",
      "map\n",
      "web\n",
      "use\n",
      "-19\n",
      "sir\n",
      "act\n",
      "oil\n",
      "gap\n",
      "paf\n",
      "due\n",
      "geo\n",
      "fit\n",
      "use\n",
      "low\n",
      "sit\n",
      "use\n",
      "era\n",
      "air\n",
      "jci\n",
      "new\n",
      "aid\n",
      "pat\n",
      "era\n",
      "end\n",
      "die\n",
      "rct\n",
      "use\n",
      "cov\n",
      "bin\n",
      "aid\n",
      "rna\n",
      "rna\n",
      "put\n",
      "use\n",
      "new\n",
      "jaw\n",
      "hiv\n",
      "use\n",
      "use\n",
      "icu\n",
      "new\n",
      "dna\n",
      "use\n",
      "oil\n",
      "big\n",
      "mhd\n",
      "tpa\n",
      "age\n",
      "sir\n",
      "use\n",
      "new\n",
      "use\n",
      "nhs\n",
      "new\n",
      "dna\n",
      "win\n",
      "use\n",
      "new\n",
      "use\n",
      "usa\n",
      "new\n",
      "use\n",
      "air\n",
      "ill\n",
      "ban\n",
      "use\n",
      "amp\n",
      "fda\n",
      "aid\n",
      "new\n",
      "use\n",
      "dna\n",
      "ceo\n",
      "new\n",
      "use\n",
      "run\n",
      "bat\n",
      "dog\n",
      "low\n",
      "oil\n",
      "end\n",
      "mar\n",
      "rna\n",
      "use\n",
      "cdc\n",
      "nhs\n",
      "gps\n",
      "vet\n",
      "cop\n",
      "fda\n",
      "new\n",
      "new\n",
      "use\n",
      "add\n",
      "fdg\n",
      "fit\n",
      "lip\n",
      "big\n",
      "use\n",
      "art\n",
      "use\n",
      "get\n",
      "new\n",
      "r/s\n",
      "map\n",
      "use\n",
      "sir\n",
      "era\n",
      "cdc\n",
      "age\n",
      "use\n",
      "set\n",
      "kar\n",
      "new\n",
      "new\n",
      "era\n",
      "ten\n",
      "hot\n",
      "foe\n",
      "use\n",
      "car\n",
      "sir\n",
      "use\n",
      "use\n",
      "sir\n",
      "set\n",
      "kit\n",
      "lag\n",
      "new\n",
      "oil\n",
      "fat\n",
      "day\n",
      "crt\n",
      "era\n",
      "gap\n",
      "ill\n",
      "bed\n",
      "get\n",
      "use\n",
      "new\n",
      "net\n",
      "rna\n",
      "mnm\n",
      "eye\n",
      "acc\n",
      "rbd\n",
      "oil\n",
      "gas\n",
      "new\n",
      "way\n",
      "use\n",
      "new\n",
      "era\n",
      "key\n",
      "bad\n",
      "old\n",
      "big\n",
      "big\n",
      "war\n",
      "day\n",
      "cdc\n",
      "ill\n",
      "end\n",
      "rna\n",
      "get\n",
      "job\n",
      "dis\n",
      "use\n",
      "use\n",
      "pcr\n",
      "act\n",
      "rcp\n",
      "low\n",
      "ace\n",
      "new\n",
      "end\n",
      "new\n",
      "law\n",
      "lab\n",
      "say\n",
      "new\n",
      "law\n",
      "new\n",
      "ihr\n",
      "ill\n",
      "rna\n",
      "age\n",
      "aid\n",
      "pdb\n",
      "pdb\n",
      "app\n",
      "ppe\n",
      "lie\n",
      "cdc\n",
      "get\n",
      "use\n",
      "new\n",
      "age\n",
      "dis\n",
      "key\n",
      "dna\n",
      "new\n",
      "use\n",
      "big\n",
      "ldl\n",
      "use\n",
      "oil\n",
      "day\n",
      "mar\n",
      "get\n",
      "set\n",
      "new\n",
      "use\n",
      "cdc\n",
      "use\n",
      "set\n",
      "kit\n",
      "use\n",
      "buy\n",
      "say\n",
      "tli\n",
      "kai\n",
      "new\n",
      "key\n",
      "rna\n",
      "pam\n",
      "usa\n",
      "new\n",
      "use\n",
      "eye\n",
      "new\n",
      "use\n",
      "say\n",
      "job\n",
      "bma\n",
      "rub\n",
      "rbd\n",
      "way\n",
      "say\n",
      "buy\n",
      "get\n",
      "oil\n",
      "use\n",
      "sir\n",
      "sir\n",
      "use\n",
      "sus\n",
      "see\n",
      "iii\n",
      "org\n",
      "pay\n",
      "abo\n",
      "igg\n",
      "old\n",
      "new\n",
      "new\n",
      "apn\n",
      "prm\n",
      "ppe\n",
      "use\n",
      "air\n",
      "era\n",
      "eye\n",
      "new\n",
      "eaa\n",
      "tme\n",
      "new\n",
      "new\n",
      "ill\n",
      "ray\n",
      "bat\n",
      "use\n",
      "day\n",
      "new\n",
      "rna\n",
      "wax\n",
      "rcn\n",
      "law\n",
      "otc\n",
      "day\n",
      "use\n",
      "pcr\n",
      "ill\n",
      "mar\n",
      "use\n",
      "new\n",
      "new\n",
      "new\n",
      "key\n",
      "ill\n",
      "use\n",
      "sun\n",
      "cdc\n",
      "ban\n",
      "flu\n",
      "ctl\n",
      "dog\n",
      "new\n",
      "pdm\n",
      "old\n",
      "law\n",
      "rna\n",
      "ice\n",
      "dna\n",
      "age\n",
      "n95\n",
      "new\n",
      "pcr\n",
      "use\n",
      "lag\n",
      "cdc\n",
      "key\n",
      "rna\n",
      "use\n",
      "hiv\n",
      "flu\n",
      "new\n",
      "age\n",
      "map\n",
      "und\n",
      "vor\n",
      "new\n",
      "cdc\n",
      "win\n",
      "new\n",
      "cns\n",
      "rna\n",
      "usa\n",
      "ppg\n",
      "set\n",
      "new\n",
      "use\n",
      "net\n",
      "tax\n",
      "gps\n",
      "cqc\n",
      "cdc\n",
      "rna\n",
      "new\n",
      "run\n",
      "icu\n",
      "low\n",
      "cat\n",
      "win\n",
      "new\n",
      "rna\n",
      "pig\n",
      "old\n",
      "low\n",
      "cop\n",
      "icu\n",
      "bed\n",
      "pin\n",
      "sar\n",
      "use\n",
      "use\n",
      "pcp\n",
      "new\n",
      "use\n",
      "eat\n",
      "cdc\n",
      "end\n",
      "use\n",
      "ill\n",
      "aid\n",
      "old\n",
      "iii\n",
      "战疫债\n",
      "use\n",
      "pcr\n",
      "cdc\n",
      "bma\n",
      "new\n",
      "icu\n",
      "low\n",
      "new\n",
      "law\n",
      "atp\n",
      "rna\n",
      "use\n",
      "£94\n",
      "pay\n",
      "han\n",
      "day\n",
      "ahr\n",
      "use\n",
      "hip\n",
      "hiv\n",
      "tax\n",
      "cut\n",
      "dot\n",
      "use\n",
      "han\n",
      "cdc\n",
      "dog\n",
      "new\n",
      "due\n",
      "sex\n",
      "old\n",
      "rna\n",
      "new\n",
      "use\n",
      "sir\n",
      "day\n",
      "web\n",
      "day\n",
      "law\n",
      "new\n",
      "cdc\n",
      "rna\n",
      "age\n",
      "rna\n",
      "cdc\n",
      "eye\n",
      "lab\n",
      "low\n",
      "new\n",
      "pig\n",
      "fly\n",
      "aid\n",
      "cdc\n",
      "old\n",
      "new\n",
      "efi\n",
      "igg\n",
      "cdc\n",
      "usa\n",
      "cdc\n",
      "eye\n",
      "big\n",
      "oil\n",
      "gas\n",
      "ill\n",
      "air\n",
      "old\n",
      "rbd\n",
      "art\n",
      "war\n",
      "era\n",
      "rna\n",
      "rna\n",
      "use\n",
      "cop\n",
      "cci\n",
      "cit\n",
      "new\n",
      "cci\n",
      "cit\n",
      "jan\n",
      "feb\n",
      "new\n",
      "eir\n",
      "ncp\n",
      "key\n",
      "tos\n",
      "old\n",
      "new\n",
      "big\n",
      "due\n",
      "ban\n",
      "iii\n",
      "get\n",
      "low\n",
      "key\n",
      "low\n",
      "tos\n",
      "old\n",
      "use\n",
      "vsi\n",
      "nhs\n",
      "ill\n",
      "key\n",
      "due\n",
      "low\n",
      "air\n",
      "end\n",
      "flu\n",
      "new\n",
      "fdg\n",
      "low\n",
      "cfr\n",
      "use\n",
      "new\n",
      "pet\n",
      "dog\n",
      "cdc\n",
      "feb\n",
      "new\n",
      "hit\n",
      "new\n",
      "dog\n",
      "cdc\n",
      "gps\n",
      "bat\n",
      "hiv\n",
      "usa\n",
      "cdc\n",
      "cdc\n",
      "new\n",
      "aid\n",
      "cdc\n",
      "act\n",
      "dao\n",
      "yin\n",
      "app\n",
      "use\n",
      "new\n",
      "cdc\n",
      "due\n",
      "dic\n",
      "new\n",
      "key\n",
      "due\n",
      "rna\n",
      "ten\n",
      "cdc\n",
      "dog\n",
      "cdc\n",
      "cdc\n",
      "cdc\n",
      "bgi\n",
      "lab\n",
      "cdc\n",
      "cdc\n",
      "ink\n",
      "dye\n",
      "ion\n",
      "ink\n",
      "dye\n",
      "ion\n",
      "dna\n",
      "big\n",
      "air\n",
      "end\n",
      "law\n",
      "sir\n",
      "use\n",
      "ckd\n",
      "ns8\n",
      "cdc\n",
      "apt\n",
      "igm\n",
      "igg\n",
      "use\n",
      "use\n",
      "new\n",
      "rna\n",
      "rna\n",
      "ill\n",
      "aid\n",
      "due\n",
      "pig\n",
      "dna\n",
      "rna\n",
      "new\n",
      "due\n",
      "use\n",
      "tcm\n",
      "rna\n",
      "use\n",
      "cdc\n",
      "kit\n",
      "row\n",
      "cdc\n",
      "paf\n",
      "n95\n",
      "use\n",
      "use\n",
      "ban\n",
      "bat\n",
      "egg\n",
      "use\n",
      "new\n",
      "new\n",
      "ask\n",
      "say\n",
      "mev\n",
      "cov\n",
      "ban\n",
      "map\n",
      "new\n",
      "app\n",
      "-19\n",
      "new\n",
      "ill\n",
      "nhs\n",
      "ili\n",
      "t89\n",
      "ncp\n",
      "new\n",
      "new\n",
      "new\n",
      "caq\n",
      "ill\n",
      "end\n",
      "dna\n",
      "pig\n",
      "tdd\n",
      "ban\n",
      "say\n",
      "cmo\n",
      "new\n",
      "rsv\n",
      "use\n",
      "ill\n",
      "wyn\n",
      "nmr\n",
      "mri\n",
      "gdp\n",
      "use\n",
      "cut\n",
      "old\n",
      "new\n",
      "rna\n",
      "day\n",
      "feb\n",
      "new\n",
      "o2o\n",
      "use\n",
      "use\n",
      "rna\n",
      "cdc\n",
      "say\n",
      "low\n",
      "new\n",
      "gut\n",
      "act\n",
      "arm\n",
      "dis\n",
      "feb\n",
      "use\n",
      "ban\n",
      "age\n",
      "acp\n",
      "hbv\n",
      "rna\n",
      "rna\n",
      "new\n",
      "key\n",
      "set\n",
      "cdc\n",
      "new\n",
      "use\n",
      "rna\n",
      "dna\n",
      "rna\n",
      "use\n",
      "nhs\n",
      "bat\n",
      "der\n",
      "sri\n",
      "cdc\n",
      "new\n",
      "new\n",
      "ill\n",
      "cdc\n",
      "use\n",
      "med\n",
      "feb\n",
      "ent\n",
      "box\n",
      "law\n",
      "sex\n",
      "cdc\n",
      "cop\n",
      "med\n",
      "feb\n",
      "new\n",
      "dis\n",
      "ctl\n",
      "cea\n",
      "rna\n",
      "pcr\n",
      "rna\n",
      "jim\n",
      "it…\n",
      "low\n",
      "igg\n",
      "cdc\n",
      "rna\n",
      "pay\n",
      "way\n",
      "bat\n",
      "use\n",
      "rat\n",
      "rna\n",
      "-19\n",
      "-19\n",
      "new\n",
      "ade\n",
      "law\n",
      "app\n",
      "mir\n",
      "rna\n",
      "bat\n",
      "air\n",
      "rna\n",
      "use\n",
      "use\n",
      "new\n",
      "use\n",
      "due\n",
      "ban\n",
      "set\n",
      "one\n",
      "gas\n",
      "use\n",
      "rna\n",
      "iii\n",
      "key\n",
      "hiv\n",
      "age\n",
      "day\n",
      "new\n",
      "new\n",
      "fda\n",
      "use\n",
      "low\n",
      "use\n",
      "ill\n",
      "key\n",
      "ncp\n",
      "dot\n",
      "end\n",
      "new\n",
      "usa\n",
      "cdc\n",
      "ill\n",
      "low\n",
      "cdc\n",
      "use\n",
      "abc\n",
      "use\n",
      "rat\n",
      "fda\n",
      "use\n",
      "fda\n",
      "n95\n",
      "use\n",
      "new\n",
      "bbc\n",
      "age\n",
      "low\n",
      "way\n",
      "npc\n",
      "ncp\n",
      "use\n",
      "pcr\n",
      "old\n",
      "cat\n",
      "new\n",
      "gdf\n",
      "nir\n",
      "new\n",
      "dna\n",
      "old\n",
      "get\n",
      "new\n",
      "new\n",
      "use\n",
      "end\n",
      "new\n",
      "new\n",
      "map\n",
      "gut\n",
      "key\n",
      "new\n",
      "age\n",
      "rna\n",
      "3-c\n",
      "key\n",
      "art\n",
      "cov\n",
      "use\n",
      "new\n",
      "eye\n",
      "use\n",
      "use\n",
      "use\n",
      "p38\n",
      "cut\n",
      "use\n",
      "new\n",
      "new\n",
      "new\n",
      "big\n",
      "get\n",
      "igg\n",
      "3-c\n",
      "mva\n",
      "bad\n",
      "get\n",
      "new\n",
      "new\n",
      "law\n",
      "tlr\n",
      "egg\n",
      "use\n",
      "bma\n",
      "age\n",
      "day\n",
      "feb\n",
      "cdc\n",
      "dry\n",
      "fda\n",
      "use\n",
      "fda\n",
      "rna\n",
      "air\n",
      "end\n",
      "iga\n",
      "new\n",
      "due\n",
      "use\n",
      "end\n",
      "new\n",
      "rna\n",
      "bat\n",
      "use\n",
      "use\n",
      "use\n",
      "new\n",
      "bat\n",
      "new\n",
      "new\n",
      "use\n",
      "web\n",
      "use\n",
      "big\n",
      "old\n",
      "new\n",
      "web\n",
      "nhs\n",
      "get\n",
      "r_0\n",
      "ban\n",
      "ban\n",
      "hr1\n",
      "use\n",
      "ill\n",
      "ten\n",
      "hot\n",
      "new\n",
      "cov\n",
      "use\n",
      "new\n",
      "use\n",
      "rna\n",
      "ban\n",
      "cdc\n",
      "map\n",
      "use\n",
      "bat\n",
      "icu\n",
      "hiv\n",
      "big\n",
      "use\n",
      "egg\n",
      "rna\n",
      "new\n",
      "eye\n",
      "gps\n",
      "use\n",
      "old\n",
      "run\n",
      "use\n",
      "say\n",
      "uae\n",
      "th1\n",
      "th2\n",
      "low\n",
      "get\n",
      "cdc\n",
      "cdc\n",
      "eye\n",
      "rna\n",
      "use\n",
      "cdc\n",
      "red\n",
      "key\n",
      "rna\n",
      "era\n",
      "hiv\n",
      "sun\n",
      "new\n",
      "old\n",
      "new\n",
      "dr.\n",
      "pcr\n",
      "p38\n",
      "new\n",
      "rna\n",
      "p53\n",
      "ari\n",
      "new\n",
      "bat\n",
      "bat\n",
      "pcr\n",
      "dog\n",
      "new\n",
      "put\n",
      "new\n",
      "use\n",
      "act\n",
      "use\n",
      "new\n",
      "use\n",
      "use\n",
      "gag\n",
      "rna\n",
      "rna\n",
      "nmr\n",
      "epr\n",
      "act\n",
      "new\n",
      "rok\n",
      "use\n",
      "cov\n",
      "low\n",
      "new\n",
      "bat\n",
      "omp\n",
      "hip\n",
      "say\n",
      "aid\n",
      "dna\n",
      "old\n",
      "new\n",
      "foe\n",
      "big\n",
      "pig\n",
      "use\n",
      "men\n",
      "hts\n",
      "mud\n",
      "new\n",
      "rna\n",
      "hop\n",
      "rna\n",
      "pcr\n",
      "bat\n",
      "key\n",
      "ion\n",
      "use\n",
      "bat\n",
      "crv\n",
      "idm\n",
      "new\n",
      "new\n",
      "new\n",
      "set\n",
      "cdc\n",
      "rna\n",
      "new\n",
      "cov\n",
      "use\n",
      "pcr\n",
      "kit\n",
      "lay\n",
      "day\n",
      "jan\n",
      "cdc\n",
      "tat\n",
      "ltr\n",
      "new\n",
      "cdc\n",
      "use\n",
      "cdc\n",
      "get\n",
      "rna\n",
      "pig\n",
      "air\n",
      "low\n",
      "dna\n",
      "cns\n",
      "use\n",
      "cdc\n",
      "cdc\n",
      "pig\n",
      "cdc\n",
      "dog\n",
      "cdc\n",
      "cdc\n",
      "mat\n",
      "bat\n",
      "rna\n",
      "pig\n",
      "jnk\n",
      "cat\n",
      "cdc\n",
      "st2\n",
      "low\n",
      "rpe\n",
      "rna\n",
      "icu\n",
      "vol\n",
      "use\n",
      "key\n",
      "rna\n",
      "use\n",
      "red\n",
      "new\n",
      "use\n",
      "pig\n",
      "apn\n",
      "pis\n",
      "pcr\n",
      "dna\n",
      "rna\n",
      "pet\n",
      "ns6\n",
      "ns7\n",
      "ifn\n",
      "cdc\n",
      "dna\n",
      "rna\n",
      "cat\n",
      "use\n",
      "spp\n",
      "bat\n",
      "sea\n",
      "new\n",
      "cdc\n",
      "cdc\n",
      "iii\n",
      "cdc\n",
      "new\n",
      "web\n",
      "law\n",
      "cow\n",
      "eel\n",
      "bat\n",
      "cdc\n",
      "cdc\n",
      "use\n",
      "use\n",
      "dog\n",
      "cat\n",
      "bat\n",
      "use\n",
      "low\n",
      "use\n",
      "raw\n",
      "old\n",
      "new\n",
      "use\n",
      "new\n",
      "bat\n",
      "p38\n",
      "use\n",
      "new\n",
      "use\n",
      "web\n",
      "new\n",
      "age\n",
      "tdo\n",
      "use\n",
      "dna\n",
      "th1\n",
      "th2\n",
      "low\n",
      "ctl\n",
      "igg\n",
      "rna\n",
      "use\n",
      "rna\n",
      "new\n",
      "due\n",
      "age\n",
      "erk\n",
      "pig\n",
      "mat\n",
      "use\n",
      "pcr\n",
      "new\n",
      "rna\n",
      "use\n",
      "dna\n",
      "pig\n",
      "nmr\n",
      "rna\n",
      "bat\n",
      "bat\n",
      "sow\n",
      "rna\n",
      "pet\n",
      "new\n",
      "pet\n",
      "dna\n",
      "use\n",
      "wet\n",
      "a71\n",
      "vp1\n",
      "bat\n",
      "use\n",
      "g4p\n",
      "use\n",
      "use\n",
      "ibd\n",
      "hbv\n",
      "rat\n",
      "bat\n",
      "age\n",
      "ldh\n",
      "use\n",
      "pip\n",
      "new\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "for item in title_filtered_sentence:\n",
    "    for i in item:\n",
    "        if len(i) == 3:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDF2Vec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create data structure for knowledge graph\n",
    "def addTriple(net, source, target, edge):\n",
    "    if source in net:\n",
    "        if  target in net[source]:\n",
    "            net[source][target].add(edge)\n",
    "        else:\n",
    "            net[source][target]= set([edge])\n",
    "    else:\n",
    "        net[source]={}\n",
    "        net[source][target] =set([edge])\n",
    "            \n",
    "def getLinks(net, source):\n",
    "    if source not in net:\n",
    "        return {}\n",
    "    return net[source]\n",
    "\n",
    "# Generate paths (entity->relation->entity) by radom walks\n",
    "def randomWalkUniform(triples, startNode, max_depth=5):\n",
    "    next_node =startNode\n",
    "    path = str(startNode)+'->'\n",
    "    for i in range(max_depth):\n",
    "        neighs = getLinks(triples,next_node)\n",
    "        #print (neighs)\n",
    "        if len(neighs) == 0: break\n",
    "        weights = []\n",
    "        queue = []\n",
    "        for neigh in neighs:\n",
    "            for edge in neighs[neigh]:\n",
    "                queue.append((edge,neigh))\n",
    "        edge, next_node = random.choice(queue)\n",
    "        path = path +str(edge)+'->'\n",
    "        path = path +str(next_node)+'->'\n",
    "    path =path.split('->')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the knowledge graph structure\n",
    "def preprocess(fname):\n",
    "    triples = {}\n",
    "\n",
    "    ent_counter = 0\n",
    "    rel_counter = 0\n",
    "    train_counter = 0\n",
    "\n",
    "    print (fname)\n",
    "    #gzfile= gzip.open(fname, mode='rt')\n",
    "\n",
    "    for line in csv.reader(open(fname), delimiter='\\t', quotechar='\"'):\n",
    "        #print (line)\n",
    "        h = line[0]\n",
    "        r = line[1]\n",
    "        t = line[2]\n",
    "        \n",
    "        train_counter +=1\n",
    "\n",
    "        addTriple(triples, h, t, r)\n",
    "        train_counter+=1\n",
    "    print ('Triple:',train_counter)\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query-result.tsv\n",
      "Triple: 342982\n",
      "12144\n"
     ]
    }
   ],
   "source": [
    "file = 'query-result.tsv'\n",
    "triples = preprocess(file)\n",
    "\n",
    "entities = list(triples.keys())\n",
    "vocabulary = entities\n",
    "print (len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do random walks on the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomNWalkUniform(triples, n, walks, path_depth):\n",
    "    path=[]\n",
    "    for k in range(walks):\n",
    "        walk = randomWalkUniform(triples, n, path_depth)\n",
    "        path.append(walk)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed to generate features: 00:00:13\n"
     ]
    }
   ],
   "source": [
    "walks = 100\n",
    "path_depth = 10\n",
    "\n",
    "start_time =time.time()\n",
    "sentences =[]\n",
    "for word in vocabulary:\n",
    "    sentences.extend( randomNWalkUniform(triples, word, walks, path_depth) )\n",
    "elapsed_time = time.time() - start_time\n",
    "print ('Time elapsed to generate features:',time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = gensim.models.Word2Vec(size=300, workers=5, window=5, sg=1)\n",
    "model1.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252631606, 488685800)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_count = model1.corpus_count\n",
    "model1.train(sentences, total_examples = corpus_count, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.wv.most_similar('<https://app.dimensions.ai/details/publication/pub.1126620775>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
